{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather prediction using deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need to read the CSV file, and the float number which are represented in the following format: 10,2 convert to 10.2 and also change its type from str to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Day  Tmax  Tmin  Tmean\n",
      "0    1.57784e+09     3   0.2    1.6\n",
      "1    1.57792e+09   3.3  -0.5    1.4\n",
      "2    1.57801e+09   2.4  -0.7   0.85\n",
      "3     1.5781e+09     1   1.1   1.05\n",
      "4    1.57818e+09   3.5  -0.7    1.4\n",
      "..           ...   ...   ...    ...\n",
      "293  1.60315e+09  14.8   9.6   12.2\n",
      "294  1.60324e+09  16.6   8.9  12.75\n",
      "295  1.60332e+09  15.7  10.3     13\n",
      "296  1.60341e+09  16.4  10.8   13.6\n",
      "297   1.6035e+09  17.9  12.1     15\n",
      "\n",
      "[298 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "weather_data = pd.read_csv(\"weather_data.csv\",sep=';')\n",
    "\n",
    "features = ['Day','Tmax','Tmin','Tmean']\n",
    "df = pd.DataFrame(weather_data, columns=features)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    #print(f\"{index} : {float((row[1]).replace(',','.'))}\")\n",
    "    row[0] = pd.to_datetime(row[0])\n",
    "    row[0] = row[0].timestamp()\n",
    "    row[1] = float((row[1]).replace(',','.'))\n",
    "    row[2] = float((row[2]).replace(',','.'))\n",
    "    row[3] = float((row[3]).replace(',','.'))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have the cleared data I will create a DNNRegressor\n",
    "I will use 80% of the data to train, 10% for test and 10% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances   (238, 3), Training features   (238, 3)\n",
      "Validation instances (30, 3), Validation features (30, 3)\n",
      "Testing instances    (30, 3), Testing features    (30, 3)\n",
      "Reshaped X_tarin (238, 3, 1)\n",
      "238\n",
      "3\n",
      "Epoch 1/20\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 210.1794 - acc: 0.0042 - val_loss: 144.4475 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 112.5339 - acc: 0.0000e+00 - val_loss: 93.2457 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 85.4372 - acc: 0.0042 - val_loss: 76.4103 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 77.5794 - acc: 0.0000e+00 - val_loss: 70.0894 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 74.1799 - acc: 0.0000e+00 - val_loss: 68.4269 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 71.5591 - acc: 0.0000e+00 - val_loss: 67.5064 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 74.6594 - acc: 0.0000e+00 - val_loss: 67.1254 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 44.8740 - acc: 0.0000e+00 - val_loss: 26.6455 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 23.0334 - acc: 0.0042 - val_loss: 16.9445 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 15.3679 - acc: 0.0000e+00 - val_loss: 14.7805 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 11.0129 - acc: 0.0000e+00 - val_loss: 7.6814 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 9.1540 - acc: 0.0000e+00 - val_loss: 5.3022 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 7.6011 - acc: 0.0000e+00 - val_loss: 8.4395 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 7.5337 - acc: 0.0000e+00 - val_loss: 3.5918 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 5.8061 - acc: 0.0000e+00 - val_loss: 2.8330 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 4.6225 - acc: 0.0000e+00 - val_loss: 4.0101 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 5.8780 - acc: 0.0000e+00 - val_loss: 2.9916 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 4.6209 - acc: 0.0000e+00 - val_loss: 1.5719 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 4.1002 - acc: 0.0000e+00 - val_loss: 2.6898 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 4.7166 - acc: 0.0042 - val_loss: 2.1570 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17be806c520>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, median_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, Dropout\n",
    "\n",
    "X = df[[col for col in df.columns if col not in ['Tmean']]]\n",
    "y = df['Tmean']\n",
    "\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y, train_size=0.8, random_state=23)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_other, y_other, test_size=0.5, random_state=23)\n",
    "X_train.shape, X_test.shape, X_val.shape\n",
    "print(f\"Training instances   {X_train.shape}, Training features   {X_train.shape}\")\n",
    "print(f\"Validation instances {X_val.shape}, Validation features { X_val.shape}\")\n",
    "print(f\"Testing instances    {X_test.shape}, Testing features    {X_test.shape}\")\n",
    "\n",
    "\n",
    "#Convert data to numpy array\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "X_val= X_val.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "\n",
    "#Reshape data to have 3 dimensions\n",
    "X_train = X_train.reshape(-1,3,1)\n",
    "print(f\"Reshaped X_tarin {X_train.shape}\")\n",
    "#y_train =y_train.reshape(3,1)\n",
    "X_test = X_test.reshape(-1,3,1)\n",
    "#y_test = y_test.reshape(-1,3,1)\n",
    "X_val= X_val.reshape(-1,3,1)\n",
    "#y_val = y_val.reshape(-1,3,1)\n",
    "\n",
    "#Converting data to tensor\n",
    "X_train_tensor = tf.convert_to_tensor(X_train, dtype=float)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=float)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test,dtype=float)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=float)\n",
    "X_val_tensor = tf.convert_to_tensor(X_val,dtype=float)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val, dtype=float)\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "print(X_train_tensor.shape[0])\n",
    "print(X_train_tensor.shape[1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units=30, return_sequences=True, input_shape = (X_train_tensor.shape[0], X_train_tensor.shape[1],1))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units= 30, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units= 30, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units= 30))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 30, activation='relu'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['acc'])\n",
    "\n",
    "model.fit(X_train_tensor,y_train_tensor, epochs=EPOCHS,batch_size=BATCH_SIZE, validation_data=(X_val_tensor,y_val_tensor))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted temperature for tomorrow: 13.255533218383789\n",
      "Predicted temperature for next weak: 24.66844940185547\n",
      "Predicted temperature for the next month: 21.260074615478516\n"
     ]
    }
   ],
   "source": [
    "predicted_temperature = model.predict(X_test_tensor)\n",
    "print(f\"Predicted temperature for 28.october : {np.mean(predicted_temperature[0],axis=0) }\")\n",
    "print(f\"Predicted temperature for 3.november : {np.mean(predicted_temperature[6],axis=0) }\")\n",
    "print(f\"Predicted temperature for 24.november : {np.mean(predicted_temperature[29],axis=0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
