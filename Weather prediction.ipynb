{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather prediction using deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need to read the CSV file, and the float number which are represented in the following format: 10,2 convert to 10.2 and also change its type from str to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Day  Tmax  Tmin  Tmean\n",
      "0    1.57784e+09     3   0.2    1.6\n",
      "1    1.57792e+09   3.3  -0.5    1.4\n",
      "2    1.57801e+09   2.4  -0.7   0.85\n",
      "3     1.5781e+09     1   1.1   1.05\n",
      "4    1.57818e+09   3.5  -0.7    1.4\n",
      "..           ...   ...   ...    ...\n",
      "293  1.60315e+09  14.8   9.6   12.2\n",
      "294  1.60324e+09  16.6   8.9  12.75\n",
      "295  1.60332e+09  15.7  10.3     13\n",
      "296  1.60341e+09  16.4  10.8   13.6\n",
      "297   1.6035e+09  17.9  12.1     15\n",
      "\n",
      "[298 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "weather_data = pd.read_csv(\"weather_data.csv\",sep=';')\n",
    "\n",
    "features = ['Day','Tmax','Tmin','Tmean']\n",
    "df = pd.DataFrame(weather_data, columns=features)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    #print(f\"{index} : {float((row[1]).replace(',','.'))}\")\n",
    "    row[0] = pd.to_datetime(row[0])\n",
    "    row[0] = row[0].timestamp()\n",
    "    row[1] = float((row[1]).replace(',','.'))\n",
    "    row[2] = float((row[2]).replace(',','.'))\n",
    "    row[3] = float((row[3]).replace(',','.'))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have the cleared data I will create a DNNRegressor\n",
    "I will use 80% of the data to train, 10% for test and 10% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances   (238, 3), Training features   (238, 3)\n",
      "Validation instances (30, 3), Validation features (30, 3)\n",
      "Testing instances    (30, 3), Testing features    (30, 3)\n",
      "Reshaped X_tarin (238, 3, 1)\n",
      "238\n",
      "3\n",
      "Epoch 1/20\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 209.1972 - acc: 0.0042 - val_loss: 150.2397 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 115.0285 - acc: 0.0000e+00 - val_loss: 93.9970 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 84.4617 - acc: 0.0000e+00 - val_loss: 76.1406 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 75.4912 - acc: 0.0042 - val_loss: 70.2882 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 74.8891 - acc: 0.0042 - val_loss: 68.3930 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 75.5770 - acc: 0.0000e+00 - val_loss: 67.9572 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 57.8749 - acc: 0.0042 - val_loss: 35.1528 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 29.2782 - acc: 0.0042 - val_loss: 22.2201 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 17.8314 - acc: 0.0042 - val_loss: 15.9614 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 12.7702 - acc: 0.0084 - val_loss: 8.9437 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 8.3876 - acc: 0.0000e+00 - val_loss: 6.2338 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 8.2689 - acc: 0.0000e+00 - val_loss: 4.6138 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 7.1452 - acc: 0.0000e+00 - val_loss: 4.6403 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 6.1322 - acc: 0.0042 - val_loss: 2.7051 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 4.6976 - acc: 0.0042 - val_loss: 3.5486 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 4.7390 - acc: 0.0000e+00 - val_loss: 2.0725 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 5.5768 - acc: 0.0042 - val_loss: 1.8028 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 4.2010 - acc: 0.0000e+00 - val_loss: 2.1152 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 4.0404 - acc: 0.0000e+00 - val_loss: 1.5903 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 5.0455 - acc: 0.0084 - val_loss: 1.8754 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17ba8335430>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, median_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, Dropout\n",
    "\n",
    "X = df[[col for col in df.columns if col not in ['Tmean']]]\n",
    "y = df['Tmean']\n",
    "\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y, train_size=0.8, random_state=23)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_other, y_other, test_size=0.5, random_state=23)\n",
    "X_train.shape, X_test.shape, X_val.shape\n",
    "print(f\"Training instances   {X_train.shape}, Training features   {X_train.shape}\")\n",
    "print(f\"Validation instances {X_val.shape}, Validation features { X_val.shape}\")\n",
    "print(f\"Testing instances    {X_test.shape}, Testing features    {X_test.shape}\")\n",
    "\n",
    "\n",
    "#Convert data to numpy array\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "X_val= X_val.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "\n",
    "#Reshape data to have 3 dimensions\n",
    "X_train = X_train.reshape(-1,3,1)\n",
    "print(f\"Reshaped X_tarin {X_train.shape}\")\n",
    "#y_train =y_train.reshape(3,1)\n",
    "X_test = X_test.reshape(-1,3,1)\n",
    "#y_test = y_test.reshape(-1,3,1)\n",
    "X_val= X_val.reshape(-1,3,1)\n",
    "#y_val = y_val.reshape(-1,3,1)\n",
    "\n",
    "#Converting data to tensor\n",
    "X_train_tensor = tf.convert_to_tensor(X_train, dtype=float)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train,dtype=float)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test,dtype=float)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test,dtype=float)\n",
    "X_val_tensor = tf.convert_to_tensor(X_val,dtype=float)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val, dtype=float)\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "print(X_train_tensor.shape[0])\n",
    "print(X_train_tensor.shape[1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units=30, return_sequences=True, input_shape = (X_train_tensor.shape[0], X_train_tensor.shape[1]))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units= 30, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units= 30, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units= 30))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 30, activation='relu'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['acc'])\n",
    "\n",
    "model.fit(X_train_tensor,y_train_tensor, epochs=EPOCHS,batch_size=BATCH_SIZE, validation_data=(X_val_tensor,y_val_tensor))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted temperature for tomorrow: 7.53640079498291\n",
      "Predicted temperature for next weak: 7.5046916007995605\n",
      "Predicted temperature for the next month: 7.5889668464660645\n"
     ]
    }
   ],
   "source": [
    "predicted_temperature = model.predict(X_test_tensor)\n",
    "print(f\"Predicted temperature for tomorrow: {(predicted_temperature[0][0] + predicted_temperature[1][0])/2 }\")\n",
    "print(f\"Predicted temperature for next weak: {(predicted_temperature[0][6] + predicted_temperature[1][6])/2 }\")\n",
    "print(f\"Predicted temperature for the next month: {(predicted_temperature[0][29] + predicted_temperature[1][29])/2 }\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
